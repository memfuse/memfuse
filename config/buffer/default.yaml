# @package buffer
# Buffer configuration for MemFuse

# Buffer system enabled
enabled: true

# RoundBuffer configuration - Token-based FIFO buffer
round_buffer:
  max_tokens: 800               # Token limit before transfer to HybridBuffer
  max_size: 5                   # Maximum number of rounds before forced transfer
  token_model: "gpt-4o-mini"  # Model for token counting

# HybridBuffer configuration - Dual-format buffer with FIFO
hybrid_buffer:
  max_size: 5                   # Maximum number of items in buffer (FIFO)
  chunk_strategy: "message"     # Chunking strategy: "message" or "contextual"
  embedding_model: "all-MiniLM-L6-v2"  # Embedding model for vector generation

# Token counter configuration
token_counter:
  model: "gpt-4o-mini"       # Default model for token counting
  fallback_multiplier: 1.3     # Multiplier for word-based fallback

# Query configuration
query:
  default_sort_by: "score"     # Default sort field: "score" or "timestamp"
  default_order: "desc"        # Default sort order: "asc" or "desc"
  max_size: 15                 # Maximum results per query
  cache_size: 100              # Query cache size

# Performance settings
performance:
  batch_write_threshold: 5     # Threshold for batch writes
  flush_interval: 300          # Auto-flush interval in seconds (0 = disabled)
  enable_async_processing: true # Enable async chunk processing

# Monitoring and logging
monitoring:
  enable_stats: true           # Enable statistics collection
  log_level: "INFO"           # Log level for buffer operations
  performance_tracking: true  # Track performance metrics
